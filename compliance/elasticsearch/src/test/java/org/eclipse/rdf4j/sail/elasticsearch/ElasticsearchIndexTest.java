/*******************************************************************************
 * Copyright (c) 2015 Eclipse RDF4J contributors, Aduna, and others.
 *
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Eclipse Distribution License v1.0
 * which accompanies this distribution, and is available at
 * http://www.eclipse.org/org/documents/edl-v10.php.
 *
 * SPDX-License-Identifier: BSD-3-Clause
 *******************************************************************************/
// Some portions generated by Codex
package org.eclipse.rdf4j.sail.elasticsearch;

import static org.junit.jupiter.api.Assertions.assertEquals;
import static org.junit.jupiter.api.Assertions.assertFalse;
import static org.junit.jupiter.api.Assertions.assertNotNull;
import static org.junit.jupiter.api.Assertions.assertNull;
import static org.junit.jupiter.api.Assertions.assertTrue;
import static org.junit.jupiter.api.Assertions.fail;

import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.util.Base64;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.function.Predicate;

import org.apache.http.Header;
import org.apache.http.HttpHeaders;
import org.eclipse.rdf4j.model.IRI;
import org.eclipse.rdf4j.model.Literal;
import org.eclipse.rdf4j.model.Statement;
import org.eclipse.rdf4j.model.ValueFactory;
import org.eclipse.rdf4j.model.impl.SimpleValueFactory;
import org.eclipse.rdf4j.repository.sail.SailRepository;
import org.eclipse.rdf4j.repository.sail.SailRepositoryConnection;
import org.eclipse.rdf4j.sail.lucene.LuceneSail;
import org.eclipse.rdf4j.sail.lucene.SearchDocument;
import org.eclipse.rdf4j.sail.lucene.SearchFields;
import org.eclipse.rdf4j.sail.memory.MemoryStore;
import org.elasticsearch.client.RestClient;
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;

import com.fasterxml.jackson.core.type.TypeReference;

import co.elastic.clients.elasticsearch._types.query_dsl.Query;
import co.elastic.clients.elasticsearch._types.query_dsl.QueryBuilders;
import co.elastic.clients.elasticsearch.core.GetResponse;
import co.elastic.clients.elasticsearch.core.SearchResponse;
import co.elastic.clients.elasticsearch.core.search.Hit;

public class ElasticsearchIndexTest extends AbstractElasticsearchTest {

	private static final ValueFactory vf = SimpleValueFactory.getInstance();
	private static final java.lang.reflect.Type MAP_TYPE = new TypeReference<Map<String, Object>>() {
	}.getType();

	public static final IRI CONTEXT_1 = vf.createIRI("urn:context1");

	public static final IRI CONTEXT_2 = vf.createIRI("urn:context2");

	public static final IRI CONTEXT_3 = vf.createIRI("urn:context3");

	// create some objects that we will use throughout this test
	IRI subject = vf.createIRI("urn:subj");

	IRI subject2 = vf.createIRI("urn:subj2");

	IRI predicate1 = vf.createIRI("urn:pred1");

	IRI predicate2 = vf.createIRI("urn:pred2");

	Literal object1 = vf.createLiteral("object1");

	Literal object2 = vf.createLiteral("object2");

	Literal object3 = vf.createLiteral("cats");

	Literal object4 = vf.createLiteral("dogs");

	Literal object5 = vf.createLiteral("chicken");

	Statement statement11 = vf.createStatement(subject, predicate1, object1);

	Statement statement12 = vf.createStatement(subject, predicate2, object2);

	Statement statement21 = vf.createStatement(subject2, predicate1, object3);

	Statement statement22 = vf.createStatement(subject2, predicate2, object4);

	Statement statement23 = vf.createStatement(subject2, predicate2, object5);

	Statement statementContext111 = vf.createStatement(subject, predicate1, object1, CONTEXT_1);

	Statement statementContext121 = vf.createStatement(subject, predicate2, object2, CONTEXT_1);

	Statement statementContext211 = vf.createStatement(subject2, predicate1, object3, CONTEXT_1);

	Statement statementContext222 = vf.createStatement(subject2, predicate2, object4, CONTEXT_2);

	Statement statementContext232 = vf.createStatement(subject2, predicate2, object5, CONTEXT_2);

	ElasticsearchIndex index;

	private Properties defaultProperties() {
		Properties sailProperties = new Properties();
		sailProperties.put(ElasticsearchIndex.TRANSPORT_KEY, host + ":" + httpPort);
		sailProperties.put(ElasticsearchIndex.ELASTICSEARCH_KEY_PREFIX + "cluster.name", CLUSTER_NAME);
		sailProperties.put(ElasticsearchIndex.INDEX_NAME_KEY, ElasticsearchTestUtils.getNextTestIndexName());
		sailProperties.put(ElasticsearchIndex.WAIT_FOR_STATUS_KEY, "yellow");
		sailProperties.put(ElasticsearchIndex.WAIT_FOR_NODES_KEY, ">=1");
		return sailProperties;
	}

	@BeforeEach
	public void setUp() throws Exception {
		Properties sailProperties = defaultProperties();
		index = new ElasticsearchIndex();
		index.initialize(sailProperties);
	}

	@AfterEach
	public void tearDown() throws Exception {
		try {
			index.shutDown();
		} finally {
			index = null;
		}

		org.eclipse.rdf4j.common.concurrent.locks.Properties.setLockTrackingEnabled(false);

	}

	@Test
	public void initializeAppliesHttpCredentials() throws Exception {
		index.shutDown();

		String username = "user";
		String password = "pass";
		Properties sailProperties = defaultProperties();
		sailProperties.put(ElasticsearchIndex.ELASTICSEARCH_KEY_PREFIX + "http.username", username);
		sailProperties.put(ElasticsearchIndex.ELASTICSEARCH_KEY_PREFIX + "http.password", password);

		index = new ElasticsearchIndex();
		index.initialize(sailProperties);

		RestClient lowLevel = getLowLevelClient(index);
		List<Header> defaultHeaders = getDefaultHeaders(lowLevel);

		String expectedValue = "Basic "
				+ Base64.getEncoder().encodeToString((username + ":" + password).getBytes(StandardCharsets.UTF_8));

		assertTrue(defaultHeaders.stream().anyMatch(matchesHeader(HttpHeaders.AUTHORIZATION, expectedValue)),
				"Authorization header should be propagated to the HTTP client");
	}

	@Test
	public void testAddStatement() throws IOException {
		String predicate1Field = ElasticsearchIndex.toPropertyFieldName(SearchFields.getPropertyField(predicate1));
		String predicate2Field = ElasticsearchIndex.toPropertyFieldName(SearchFields.getPropertyField(predicate2));

		// add a statement to an index
		index.begin();
		index.addStatement(statement11);
		index.commit();

		// check that it arrived properly
		long count = countAll();
		assertEquals(1, count);

		SearchResponse<Map<String, Object>> hits = search(QueryBuilders.term(
				t -> t.field(SearchFields.URI_FIELD_NAME).value(subject.toString())));
		Iterator<Hit<Map<String, Object>>> docs = hits.hits().hits().iterator();
		assertTrue(docs.hasNext());

		Hit<Map<String, Object>> doc = docs.next();
		Map<String, Object> fields = getDoc(doc.index(), doc.id());
		assertEquals(subject.toString(), fields.get(SearchFields.URI_FIELD_NAME));
		assertEquals(object1.getLabel(), fields.get(predicate1Field));

		assertFalse(docs.hasNext());

		// add another statement
		index.begin();
		index.addStatement(statement12);
		index.commit();

		// See if everything remains consistent. We must create a new
		// IndexReader
		// in order to be able to see the updates
		count = countAll();
		assertEquals(1, count); // #docs should *not* have increased

		hits = search(QueryBuilders.term(t -> t.field(SearchFields.URI_FIELD_NAME).value(subject.toString())));
		docs = hits.hits().hits().iterator();
		assertTrue(docs.hasNext());

		doc = docs.next();
		fields = getDoc(doc.index(), doc.id());
		assertEquals(subject.toString(), fields.get(SearchFields.URI_FIELD_NAME));
		assertEquals(object1.getLabel(), fields.get(predicate1Field));
		assertEquals(object2.getLabel(), fields.get(predicate2Field));

		assertFalse(docs.hasNext());

		// see if we can query for these literals
		count = countForQuery(QueryBuilders.queryString(q -> q.query(object1.getLabel())
				.defaultField(SearchFields.TEXT_FIELD_NAME)));
		assertEquals(1, count);

		count = countForQuery(QueryBuilders.queryString(q -> q.query(object2.getLabel())
				.defaultField(SearchFields.TEXT_FIELD_NAME)));
		assertEquals(1, count);

		// remove the first statement
		index.begin();
		index.removeStatement(statement11);
		index.commit();

		// check that that statement is actually removed and that the other
		// still
		// exists

		count = countAll();
		assertEquals(1, count);

		hits = search(QueryBuilders.term(t -> t.field(SearchFields.URI_FIELD_NAME).value(subject.toString())));
		docs = hits.hits().hits().iterator();
		assertTrue(docs.hasNext());

		doc = docs.next();
		fields = getDoc(doc.index(), doc.id());
		assertEquals(subject.toString(), fields.get(SearchFields.URI_FIELD_NAME));
		assertNull(fields.get(predicate1.toString()));
		assertEquals(object2.getLabel(), fields.get(predicate2Field));

		assertFalse(docs.hasNext());

		// remove the other statement
		index.begin();
		index.removeStatement(statement12);
		index.commit();

		// check that there are no documents left (i.e. the last Document was
		// removed completely, rather than its remaining triple removed)

		count = countAll();
		assertEquals(0, count);
	}

	@Test
	public void testAddMultiple() throws Exception {
		// add a statement to an index
		HashSet<Statement> added = new HashSet<>();
		HashSet<Statement> removed = new HashSet<>();
		added.add(statement11);
		added.add(statement12);
		added.add(statement21);
		added.add(statement22);
		index.begin();
		index.addRemoveStatements(added, removed);
		index.commit();

		// check that it arrived properly

		long count = countAll();
		assertEquals(2, count);

		// check the documents
		SearchDocument document = index.getDocuments(subject).iterator().next();
		assertEquals(subject.toString(), document.getResource());
		assertStatement(statement11, document);
		assertStatement(statement12, document);

		document = index.getDocuments(subject2).iterator().next();
		assertEquals(subject2.toString(), document.getResource());
		assertStatement(statement21, document);
		assertStatement(statement22, document);

		// check if the text field stores all added string values
		HashSet<String> texts = new HashSet<>(List.of("cats", "dogs"));
		// FIXME
		// assertTexts(texts, document);

		// add/remove one
		added.clear();
		removed.clear();
		added.add(statement23);
		removed.add(statement22);
		index.begin();
		index.addRemoveStatements(added, removed);
		index.commit();

		// check doc 2
		document = index.getDocuments(subject2).iterator().next();
		assertEquals(subject2.toString(), document.getResource());
		assertStatement(statement21, document);
		assertStatement(statement23, document);
		assertNoStatement(statement22, document);

		// check if the text field stores all added and no deleted string values
		texts.remove("dogs");
		texts.add("chicken");
		// FIXME
		// assertTexts(texts, document);

		// TODO: check deletion of the rest

	}

	/**
	 * Contexts can only be tested in combination with a sail, as the triples have to be retrieved from the sail
	 *
	 * @throws Exception
	 */
	@Test
	public void testContexts() throws Exception {
		// add a sail
		MemoryStore memoryStore = new MemoryStore();
		// enable lock tracking
		org.eclipse.rdf4j.common.concurrent.locks.Properties.setLockTrackingEnabled(true);
		LuceneSail sail = new LuceneSail();
		sail.setBaseSail(memoryStore);
		sail.setLuceneIndex(index);

		// create a Repository wrapping the LuceneSail
		SailRepository repository = new SailRepository(sail);

		// now add the statements through the repo
		// add statements with context
		try (SailRepositoryConnection connection = repository.getConnection()) {
			connection.begin();
			connection.add(statementContext111, statementContext111.getContext());
			connection.add(statementContext121, statementContext121.getContext());
			connection.add(statementContext211, statementContext211.getContext());
			connection.add(statementContext222, statementContext222.getContext());
			connection.add(statementContext232, statementContext232.getContext());
			connection.commit();

			// check if they are there
			assertStatement(statementContext111);
			assertStatement(statementContext121);
			assertStatement(statementContext211);
			assertStatement(statementContext222);
			assertStatement(statementContext232);

			// delete context 1
			connection.begin();
			connection.clear(CONTEXT_1);
			connection.commit();
			assertNoStatement(statementContext111);
			assertNoStatement(statementContext121);
			assertNoStatement(statementContext211);
			assertStatement(statementContext222);
			assertStatement(statementContext232);
		} finally {
			// close repo
			repository.shutDown();
		}
	}

	/**
	 * Contexts can only be tested in combination with a sail, as the triples have to be retrieved from the sail
	 *
	 * @throws Exception
	 */
	@Test
	public void testContextsRemoveContext2() throws Exception {
		// add a sail
		MemoryStore memoryStore = new MemoryStore();
		// enable lock tracking
		org.eclipse.rdf4j.common.concurrent.locks.Properties.setLockTrackingEnabled(true);
		LuceneSail sail = new LuceneSail();
		sail.setBaseSail(memoryStore);
		sail.setLuceneIndex(index);

		// create a Repository wrapping the LuceneSail
		SailRepository repository = new SailRepository(sail);

		// now add the statements through the repo
		// add statements with context
		try (SailRepositoryConnection connection = repository.getConnection()) {
			connection.begin();
			connection.add(statementContext111, statementContext111.getContext());
			connection.add(statementContext121, statementContext121.getContext());
			connection.add(statementContext211, statementContext211.getContext());
			connection.add(statementContext222, statementContext222.getContext());
			connection.add(statementContext232, statementContext232.getContext());
			connection.commit();

			// check if they are there
			assertStatement(statementContext111);
			assertStatement(statementContext121);
			assertStatement(statementContext211);
			assertStatement(statementContext222);
			assertStatement(statementContext232);

			// delete context 2
			connection.begin();
			connection.clear(CONTEXT_2);
			connection.commit();
			assertStatement(statementContext111);
			assertStatement(statementContext121);
			assertStatement(statementContext211);
			assertNoStatement(statementContext222);
			assertNoStatement(statementContext232);
		} finally {
			// close repo
			repository.shutDown();
		}
	}

	@Test
	public void testRejectedDatatypes() {
		IRI STRING = vf.createIRI("http://www.w3.org/2001/XMLSchema#string");
		IRI FLOAT = vf.createIRI("http://www.w3.org/2001/XMLSchema#float");
		Literal literal1 = vf.createLiteral("hi there");
		Literal literal2 = vf.createLiteral("hi there, too", STRING);
		Literal literal3 = vf.createLiteral("1.0");
		Literal literal4 = vf.createLiteral("1.0", FLOAT);
		assertTrue(index.accept(literal1), "Is the first literal accepted?");
		assertTrue(index.accept(literal2), "Is the second literal accepted?");
		assertTrue(index.accept(literal3), "Is the third literal accepted?");
		assertFalse(index.accept(literal4), "Is the fourth literal accepted?");
	}

	private SearchResponse<Map<String, Object>> search(Query query) throws IOException {
		return client.search(s -> s.index(index.getIndexName()).query(query), MAP_TYPE);
	}

	private long countForQuery(Query query) throws IOException {
		SearchResponse<Map<String, Object>> resp = client.search(
				s -> s.index(index.getIndexName())
						.size(0)
						.query(query)
						.trackTotalHits(th -> th.enabled(true)),
				MAP_TYPE);
		return resp.hits().total().value();
	}

	private RestClient getLowLevelClient(ElasticsearchIndex elasticsearchIndex) throws Exception {
		var field = ElasticsearchIndex.class.getDeclaredField("lowLevelClient");
		field.setAccessible(true);
		return (RestClient) field.get(elasticsearchIndex);
	}

	@SuppressWarnings("unchecked")
	private List<Header> getDefaultHeaders(RestClient restClient) throws Exception {
		var field = RestClient.class.getDeclaredField("defaultHeaders");
		field.setAccessible(true);
		return (List<Header>) field.get(restClient);
	}

	private Predicate<Header> matchesHeader(String name, String value) {
		return header -> name.equalsIgnoreCase(header.getName()) && value.equals(header.getValue());
	}

	private long countAll() throws IOException {
		return countForQuery(QueryBuilders.matchAll(m -> m));
	}

	private Map<String, Object> getDoc(String indexName, String id) throws IOException {
		GetResponse<Map<String, Object>> response = client.get(g -> g.index(indexName).id(id), MAP_TYPE);
		return response.source();
	}

	private void assertStatement(Statement statement) throws Exception {
		SearchDocument document = index.getDocument(statement.getSubject(), statement.getContext());
		if (document == null) {
			fail("Missing document " + statement.getSubject());
		}
		assertStatement(statement, document);
	}

	private void assertNoStatement(Statement statement) throws Exception {
		SearchDocument document = index.getDocument(statement.getSubject(), statement.getContext());
		if (document == null) {
			return;
		}
		assertNoStatement(statement, document);
	}

	private void assertStatement(Statement statement, SearchDocument document) {
		List<String> fields = document.getProperty(SearchFields.getPropertyField(statement.getPredicate()));
		assertNotNull(fields, "field " + statement.getPredicate() + " not found in document " + document);
		for (String f : fields) {
			if (((Literal) statement.getObject()).getLabel().equals(f)) {
				return;
			}
		}
		fail("Statement not found in document " + statement);
	}

	private void assertNoStatement(Statement statement, SearchDocument document) {
		List<String> fields = document.getProperty(SearchFields.getPropertyField(statement.getPredicate()));
		if (fields == null) {
			return;
		}
		for (String f : fields) {
			if (((Literal) statement.getObject()).getLabel().equals(f)) {
				fail("Statement should not be found in document " + statement);
			}
		}

	}

	/*
	 * private void assertTexts(Set<String> texts, Document document) { Set<String> toFind = new HashSet<String>(texts);
	 * Set<String> found = new HashSet<String>(); for(Field field : document.getFields(LuceneIndex.TEXT_FIELD_NAME)) {
	 * // is the field value expected and not yet been found? if(toFind.remove(field.stringValue())) { // add it to the
	 * found set // (it was already remove from the toFind list in the if clause) found.add(field.stringValue()); } else
	 * { assertEquals( "Was the text value '" + field.stringValue() + "' expected to exist?", false, true); } }
	 * for(String notFound : toFind) { assertEquals("Was the expected text value '" + notFound + "' found?", true,
	 * false); } }
	 */
}
