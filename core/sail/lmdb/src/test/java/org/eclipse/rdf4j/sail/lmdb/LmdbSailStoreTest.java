/*******************************************************************************
 * Copyright (c) 2021 Eclipse RDF4J contributors.
 *
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Eclipse Distribution License v1.0
 * which accompanies this distribution, and is available at
 * http://www.eclipse.org/org/documents/edl-v10.php.
 *
 * SPDX-License-Identifier: BSD-3-Clause
 *******************************************************************************/
// Some portions generated by Codex
package org.eclipse.rdf4j.sail.lmdb;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;

import java.io.File;
import java.io.IOException;
import java.util.HashSet;
import java.util.Set;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicReference;

import org.eclipse.rdf4j.common.iteration.CloseableIteration;
import org.eclipse.rdf4j.common.iteration.EmptyIteration;
import org.eclipse.rdf4j.common.transaction.IsolationLevels;
import org.eclipse.rdf4j.model.IRI;
import org.eclipse.rdf4j.model.Resource;
import org.eclipse.rdf4j.model.Statement;
import org.eclipse.rdf4j.model.ValueFactory;
import org.eclipse.rdf4j.model.impl.SimpleValueFactory;
import org.eclipse.rdf4j.model.vocabulary.RDFS;
import org.eclipse.rdf4j.query.TupleQuery;
import org.eclipse.rdf4j.query.TupleQueryResult;
import org.eclipse.rdf4j.repository.Repository;
import org.eclipse.rdf4j.repository.RepositoryConnection;
import org.eclipse.rdf4j.repository.sail.SailRepository;
import org.eclipse.rdf4j.sail.SailException;
import org.eclipse.rdf4j.sail.base.SailDataset;
import org.eclipse.rdf4j.sail.base.SailSink;
import org.eclipse.rdf4j.sail.base.SailSource;
import org.eclipse.rdf4j.sail.lmdb.config.LmdbStoreConfig;
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.io.TempDir;

/**
 * Extended test for {@link LmdbStore}.
 */
public class LmdbSailStoreTest {

	protected Repository repo;

	protected final ValueFactory F = SimpleValueFactory.getInstance();

	protected final IRI CTX_1 = F.createIRI("urn:one");
	protected final IRI CTX_2 = F.createIRI("urn:two");
	protected final IRI CTX_INV = F.createIRI("urn:invalid");

	protected final Statement S0 = F.createStatement(F.createIRI("http://example.org/0"), RDFS.LABEL,
			F.createLiteral("zero"));
	protected final Statement S1 = F.createStatement(F.createIRI("http://example.org/1"), RDFS.LABEL,
			F.createLiteral("one"));
	protected final Statement S2 = F.createStatement(F.createIRI("http://example.org/2"), RDFS.LABEL,
			F.createLiteral("two"));

	@BeforeEach
	public void before(@TempDir File dataDir) {
		repo = new SailRepository(new LmdbStore(dataDir, new LmdbStoreConfig("spoc,posc")));
		repo.init();

		try (RepositoryConnection conn = repo.getConnection()) {
			conn.add(S0);
			conn.add(S1, CTX_1);
			conn.add(S2, CTX_2);
		}
	}

	@Test
	public void testRemoveValidContext() {
		try (RepositoryConnection conn = repo.getConnection()) {
			conn.remove((IRI) null, null, null, CTX_1);
		}
		try (RepositoryConnection conn = repo.getConnection()) {
			assertTrue("Statement 0 incorrectly removed", conn.hasStatement(S0, false));
			assertFalse("Statement 1 still not removed", conn.hasStatement(S1, false, CTX_1));
			assertTrue("Statement 2 incorrectly removed", conn.hasStatement(S2, false, CTX_2));
		}
	}

	@Test
	public void testRemoveEmptyContext() {
		try (RepositoryConnection conn = repo.getConnection()) {
			conn.remove((IRI) null, null, null, (Resource) null);
		}
		try (RepositoryConnection conn = repo.getConnection()) {
			assertFalse("Statement 0 still not removed", conn.hasStatement(S0, false));
			assertTrue("Statement 1 incorrectly removed", conn.hasStatement(S1, false, CTX_1));
			assertTrue("Statement 2 incorrectly removed", conn.hasStatement(S2, false, CTX_2));
		}
	}

	@Test
	public void testRemoveInvalidContext() {
		try (RepositoryConnection conn = repo.getConnection()) {
			conn.remove((IRI) null, null, null, CTX_INV);
		}
		try (RepositoryConnection conn = repo.getConnection()) {
			assertTrue("Statement 0 incorrectly removed", conn.hasStatement(S0, false));
			assertTrue("Statement 1 incorrectly removed", conn.hasStatement(S1, false, CTX_1));
			assertTrue("Statement 2 incorrectly removed", conn.hasStatement(S2, false, CTX_2));
		}
	}

	@Test
	public void testRemoveMultipleValidContext() {
		try (RepositoryConnection conn = repo.getConnection()) {
			conn.remove((IRI) null, null, null, CTX_1, CTX_2);
		}
		try (RepositoryConnection conn = repo.getConnection()) {
			assertTrue("Statement 0 incorrectly removed", conn.hasStatement(S0, false));
			assertFalse("Statement 1 still not removed", conn.hasStatement(S1, false, CTX_1));
			assertFalse("Statement 2 still not removed", conn.hasStatement(S2, false, CTX_2));
		}
	}

	@Test
	public void testClearMultipleValidContext() {
		try (RepositoryConnection conn = repo.getConnection()) {
			conn.clear(CTX_1, CTX_2);
		}
		try (RepositoryConnection conn = repo.getConnection()) {
			assertTrue("Statement 0 incorrectly removed", conn.hasStatement(S0, false));
			assertFalse("Statement 1 still not removed", conn.hasStatement(S1, false, CTX_1));
			assertFalse("Statement 2 still not removed", conn.hasStatement(S2, false, CTX_2));
		}
	}

	@Test
	public void testPassConnectionBetweenThreads() throws InterruptedException {
		RepositoryConnection[] conn = { null };
		TupleQuery[] query = { null };
		TupleQueryResult[] result = { null };

		try {
			Thread t = new Thread(() -> {
				conn[0] = repo.getConnection();
			});
			t.start();
			t.join();

			t = new Thread(() -> {
				query[0] = conn[0].prepareTupleQuery("select * { ?s ?p ?o } ");
			});
			t.start();
			t.join();

			t = new Thread(() -> {
				result[0] = query[0].evaluate();
			});
			t.start();
			t.join();

			assertEquals(3, result[0].stream().count());
		} finally {
			conn[0].close();
		}
	}

	@Test
	public void testPassConnectionBetweenThreadsWithTx() throws InterruptedException {
		RepositoryConnection[] conn = { null };
		TupleQuery[] query = { null };
		TupleQueryResult[] result = { null };

		try {
			Thread t = new Thread(() -> {
				conn[0] = repo.getConnection();
				conn[0].setIsolationLevel(IsolationLevels.READ_UNCOMMITTED);
				conn[0].begin();
			});
			t.start();
			t.join();

			t = new Thread(() -> {
				query[0] = conn[0].prepareTupleQuery("select * { ?s ?p ?o } ");
			});
			t.start();
			t.join();

			t = new Thread(() -> {
				result[0] = query[0].evaluate();
			});
			t.start();
			t.join();

			if (result[0].hasNext()) {
				conn[0].commit();
			}
			assertEquals(3, result[0].stream().count());
		} finally {
			conn[0].close();
		}
	}

	@Test
	public void testInferredSourceHasEmptyIterationWithoutInferredStatements() throws SailException {
		LmdbStore sail = (LmdbStore) ((SailRepository) repo).getSail();
		LmdbSailStore backingStore = sail.getBackingStore();

		try (SailDataset dataset = backingStore.getInferredSailSource().dataset(IsolationLevels.NONE);
				CloseableIteration<? extends Statement> iteration = dataset.getStatements(null, null, null)) {
			assertTrue(iteration instanceof EmptyIteration);
			assertFalse(iteration.hasNext());
		}
	}

	@Test
	public void testLazyValueResolutionAfterConcurrentDelete() throws Exception {
		LmdbStore sail = (LmdbStore) ((SailRepository) repo).getSail();
		LmdbSailStore backingStore = sail.getBackingStore();
		ValueStore valueStore = backingStore.getValueStore();
		IRI subj = F.createIRI("http://example.org/temp");
		IRI pred = F.createIRI("http://example.org/p");
		var literal = F.createLiteral("temp");

		try (RepositoryConnection conn = repo.getConnection()) {
			conn.add(subj, pred, literal);
		}
		Statement stmt;
		try (SailDataset dataset = backingStore.getExplicitSailSource().dataset(IsolationLevels.READ_COMMITTED)) {
			try (CloseableIteration<? extends Statement> iter = dataset.getStatements(subj, pred, null)) {
				assertTrue(iter.hasNext());
				stmt = iter.next();
			}

			try (RepositoryConnection conn = repo.getConnection()) {
				conn.begin();
				conn.remove(subj, pred, literal);
				conn.commit();
			}

			long objId = valueStore.getId(literal);
			Set<Long> ids = new HashSet<>();
			ids.add(objId);
			valueStore.gcIds(ids, new HashSet<>());

			assertNotNull(stmt.getObject().stringValue());
		}
	}

	@Test
	public void testCommitDoesNotExposePartialState(@TempDir File dataDir) throws Exception {
		CountDownLatch commitReached = new CountDownLatch(1);
		CountDownLatch allowCommit = new CountDownLatch(1);
		BlockingCommitLmdbSailStore store = new BlockingCommitLmdbSailStore(dataDir,
				new LmdbStoreConfig("spoc,posc"), commitReached, allowCommit);
		AtomicReference<Throwable> commitFailure = new AtomicReference<>();
		ExecutorService readerExecutor = Executors.newSingleThreadExecutor();
		Future<Boolean> readerFuture = null;
		Thread commitThread = null;
		try {
			LmdbSailStore.ConnectionSailStore readerStore = store.createConnectionStore();

			IRI subj = F.createIRI("urn:commit");
			IRI pred = F.createIRI("urn:predicate");
			var literal = F.createLiteral("value");

			commitThread = new Thread(() -> {
				try {
					LmdbSailStore.ConnectionSailStore writerStore = store.createConnectionStore();
					SailSource writerSource = writerStore.getExplicitSailSource();
					SailSink writerSink = writerSource.sink(IsolationLevels.SNAPSHOT_READ);
					writerSink.approve(subj, pred, literal, null);
					writerSink.flush();
					writerSink.close();
				} catch (Throwable t) {
					commitFailure.set(t);
				}
			});
			commitThread.start();

			assertTrue("Commit did not reach value store phase in time", commitReached.await(10, TimeUnit.SECONDS));

			readerFuture = readerExecutor.submit(() -> {
				SailSource readerSource = readerStore.getExplicitSailSource();
				try (SailDataset dataset = readerSource.dataset(IsolationLevels.SNAPSHOT_READ);
						CloseableIteration<? extends Statement> iter = dataset.getStatements(subj, pred, null)) {
					if (!iter.hasNext()) {
						return false;
					}
					Statement statement = iter.next();
					return statement.getObject().stringValue() != null;
				}
			});

			try {
				readerFuture.get(200, TimeUnit.MILLISECONDS);
				fail("Reader should block while commit is in progress");
			} catch (TimeoutException expected) {
				// expected: commit lock should block readers
			}

			allowCommit.countDown();
			assertTrue("Reader did not complete after commit", readerFuture.get(10, TimeUnit.SECONDS));
		} finally {
			allowCommit.countDown();
			if (readerFuture != null) {
				readerFuture.cancel(true);
			}
			readerExecutor.shutdownNow();
			if (commitThread != null) {
				commitThread.join(TimeUnit.SECONDS.toMillis(10));
			}
			if (commitFailure.get() != null) {
				throw new AssertionError("Commit failed unexpectedly", commitFailure.get());
			}
			store.close();
		}
	}

	@Test
	public void testSnapshotBeginBlocksDuringCommit(@TempDir File dataDir) throws Exception {
		CountDownLatch commitReached = new CountDownLatch(1);
		CountDownLatch allowCommit = new CountDownLatch(1);
		BlockingCommitLmdbSailStore store = new BlockingCommitLmdbSailStore(dataDir,
				new LmdbStoreConfig("spoc,posc"), commitReached, allowCommit);
		AtomicReference<Throwable> commitFailure = new AtomicReference<>();
		ExecutorService beginExecutor = Executors.newSingleThreadExecutor();
		Future<?> beginFuture = null;
		Thread commitThread = null;
		try {
			IRI subj = F.createIRI("urn:begin");
			IRI pred = F.createIRI("urn:predicate");
			var literal = F.createLiteral("value");

			commitThread = new Thread(() -> {
				try {
					LmdbSailStore.ConnectionSailStore writerStore = store.createConnectionStore();
					SailSource writerSource = writerStore.getExplicitSailSource();
					SailSink writerSink = writerSource.sink(IsolationLevels.SNAPSHOT_READ);
					writerSink.approve(subj, pred, literal, null);
					writerSink.flush();
					writerSink.close();
				} catch (Throwable t) {
					commitFailure.set(t);
				}
			});
			commitThread.start();

			assertTrue("Commit did not reach value store phase in time", commitReached.await(10, TimeUnit.SECONDS));

			beginFuture = beginExecutor.submit(() -> {
				LmdbSailStore.ConnectionSailStore readerStore = store.createConnectionStore();
				try {
					readerStore.initTransaction(IsolationLevels.SNAPSHOT);
				} finally {
					readerStore.endTransaction(false);
				}
			});

			try {
				beginFuture.get(200, TimeUnit.MILLISECONDS);
				fail("Transaction begin should block while commit is in progress");
			} catch (TimeoutException expected) {
				// expected: commit lock should block begin
			}

			allowCommit.countDown();
			beginFuture.get(10, TimeUnit.SECONDS);
		} finally {
			allowCommit.countDown();
			if (beginFuture != null) {
				beginFuture.cancel(true);
			}
			beginExecutor.shutdownNow();
			if (commitThread != null) {
				commitThread.join(TimeUnit.SECONDS.toMillis(10));
			}
			if (commitFailure.get() != null) {
				throw new AssertionError("Commit failed unexpectedly", commitFailure.get());
			}
			store.close();
		}
	}

	@Test
	public void testSnapshotConcurrentWritesDoNotDeadlock(@TempDir File dataDir) throws Exception {
		ExecutorService executor = Executors.newSingleThreadExecutor(runnable -> {
			Thread thread = new Thread(runnable, "lmdb-snapshot-write-test");
			thread.setDaemon(true);
			return thread;
		});
		Future<?> future = executor.submit(() -> {
			Repository localRepo = new SailRepository(new LmdbStore(dataDir, new LmdbStoreConfig("spoc,posc")));
			localRepo.init();
			try (RepositoryConnection first = localRepo.getConnection();
					RepositoryConnection second = localRepo.getConnection()) {
				first.begin(IsolationLevels.SNAPSHOT_READ);
				second.begin(IsolationLevels.SNAPSHOT_READ);
				IRI subj1 = F.createIRI("urn:first");
				IRI subj2 = F.createIRI("urn:second");
				first.add(subj1, RDFS.LABEL, F.createLiteral("one"));
				second.add(subj2, RDFS.LABEL, F.createLiteral("two"));
				first.commit();
				second.commit();
			} finally {
				localRepo.shutDown();
			}
		});
		try {
			future.get(2, TimeUnit.SECONDS);
		} catch (TimeoutException e) {
			fail("Concurrent snapshot writes should not deadlock");
		} finally {
			future.cancel(true);
			executor.shutdownNow();
		}
	}

	private static final class BlockingCommitLmdbSailStore extends LmdbSailStore {

		private final CountDownLatch commitReached;
		private final CountDownLatch allowCommit;

		BlockingCommitLmdbSailStore(File dataDir, LmdbStoreConfig config, CountDownLatch commitReached,
				CountDownLatch allowCommit)
				throws IOException, SailException {
			super(dataDir, config);
			this.commitReached = commitReached;
			this.allowCommit = allowCommit;
		}

		@Override
		void handleRemovedIdsInValueStore() throws IOException {
			commitReached.countDown();
			try {
				if (!allowCommit.await(10, TimeUnit.SECONDS)) {
					throw new IOException("Timed out waiting to resume commit");
				}
			} catch (InterruptedException e) {
				Thread.currentThread().interrupt();
				throw new IOException("Interrupted while waiting to resume commit", e);
			}
			super.handleRemovedIdsInValueStore();
		}
	}

	@AfterEach
	public void after() {
		repo.shutDown();
	}
}
