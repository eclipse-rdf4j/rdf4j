/*******************************************************************************
 * Copyright (c) 2025 Eclipse RDF4J contributors.
 *
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Eclipse Distribution License v1.0
 * which accompanies this distribution, and is available at
 * http://www.eclipse.org/org/documents/edl-v10.php.
 *
 * SPDX-License-Identifier: BSD-3-Clause
 *******************************************************************************/
// Some portions generated by Codex
package org.eclipse.rdf4j.tools.optimizer.harness;

import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.Comparator;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.stream.Collectors;

import org.eclipse.rdf4j.model.Statement;
import org.eclipse.rdf4j.query.BindingSet;
import org.eclipse.rdf4j.query.QueryLanguage;
import org.eclipse.rdf4j.query.QueryResults;
import org.eclipse.rdf4j.query.TupleQuery;
import org.eclipse.rdf4j.query.TupleQueryResult;
import org.eclipse.rdf4j.query.explanation.Explanation;
import org.eclipse.rdf4j.query.explanation.GenericPlanNode;
import org.eclipse.rdf4j.repository.RepositoryConnection;
import org.eclipse.rdf4j.repository.sail.SailRepository;
import org.eclipse.rdf4j.sail.memory.MemoryStore;

public final class HarnessRunner {

	private static final String OPTIMIZER_FLAG = "rdf4j.optimizer.unionOptional.enabled";

	public static void main(String[] args) throws Exception {
		HarnessConfig config = HarnessConfig.fromArgs(args);
		Files.createDirectories(config.outputDir);

		List<Statement> statements = DatasetGenerator.generate(config);
		List<QueryCase> queries = QueryGenerator.generate(config);

		RunResult baseline = runProfile("baseline", false, statements, queries, config,
				config.outputDir.resolve("baseline.csv"));
		if (config.baselineOnly) {
			printSummary("baseline", baseline, config.outputDir.resolve("baseline-summary.txt"));
			return;
		}

		RunResult candidate = runProfile("candidate", true, statements, queries, config,
				config.outputDir.resolve("candidate.csv"));

		printSummary("baseline", baseline, config.outputDir.resolve("baseline-summary.txt"));
		printSummary("candidate", candidate, config.outputDir.resolve("candidate-summary.txt"));

		compareResults(baseline, candidate, config);
	}

	private static RunResult runProfile(String profileName, boolean enableOptimizers, List<Statement> statements,
			List<QueryCase> queries, HarnessConfig config, Path csvPath) throws Exception {
		System.setProperty(OPTIMIZER_FLAG, Boolean.toString(enableOptimizers));
		RunResult result = new RunResult(profileName);
		Path plansDir = config.outputDir.resolve("plans");
		Files.createDirectories(plansDir);

		SailRepository repository = new SailRepository(new MemoryStore());
		repository.init();
		try (RepositoryConnection connection = repository.getConnection()) {
			connection.add(statements);
			try (PlanMetricsWriter writer = new PlanMetricsWriter(csvPath)) {
				for (QueryCase queryCase : queries) {
					QueryOutcome outcome = executeQuery(connection, queryCase, writer, profileName, plansDir,
							config);
					result.outcomes.put(queryCase.id, outcome);
					result.estimationErrors.addAll(outcome.estimationErrors);
				}
			}
		} finally {
			repository.shutDown();
		}
		return result;
	}

	private static QueryOutcome executeQuery(RepositoryConnection connection, QueryCase queryCase,
			PlanMetricsWriter writer, String runId, Path plansDir, HarnessConfig config) throws IOException {
		TupleQuery query = connection.prepareTupleQuery(QueryLanguage.SPARQL, queryCase.query);
		Map<String, Long> multiset;
		try (TupleQueryResult result = query.evaluate()) {
			List<BindingSet> bindings = QueryResults.asList(result);
			multiset = toMultiset(bindings);
		}

		Explanation explanation = query.explain(Explanation.Level.Timed);
		GenericPlanNode plan = explanation.toGenericPlanNode();
		writer.writePlan(runId, queryCase.id, plan);

		double totalTimeMs = plan.getTotalTimeActual() == null ? 0.0 : plan.getTotalTimeActual();
		String planText = plan.toString();
		List<EstimationError> errors = new ArrayList<>();
		collectEstimationErrors(queryCase.id, plan, "0", errors);

		return new QueryOutcome(multiset, totalTimeMs, planText, errors);
	}

	private static void compareResults(RunResult baseline, RunResult candidate, HarnessConfig config)
			throws IOException {
		List<String> mismatches = new ArrayList<>();
		List<String> regressions = new ArrayList<>();

		for (Map.Entry<String, QueryOutcome> entry : baseline.outcomes.entrySet()) {
			String queryId = entry.getKey();
			QueryOutcome base = entry.getValue();
			QueryOutcome cand = candidate.outcomes.get(queryId);
			if (cand == null) {
				mismatches.add(queryId + ": candidate missing");
				continue;
			}
			if (!Objects.equals(base.multiset, cand.multiset)) {
				mismatches.add(queryId);
				writePlanDump(config.outputDir, queryId, base.planText, cand.planText);
				continue;
			}
			if (base.totalTimeMs > 0 && cand.totalTimeMs > base.totalTimeMs * (1.0 + config.maxRegression)) {
				regressions.add(queryId + " baseline=" + base.totalTimeMs + "ms candidate=" + cand.totalTimeMs + "ms");
				writePlanDump(config.outputDir, queryId, base.planText, cand.planText);
			}
		}

		if (!mismatches.isEmpty() || !regressions.isEmpty()) {
			StringBuilder message = new StringBuilder();
			if (!mismatches.isEmpty()) {
				message.append("Result mismatches: ")
						.append(String.join(", ", mismatches))
						.append(System.lineSeparator());
			}
			if (!regressions.isEmpty()) {
				message.append("Performance regressions: ")
						.append(String.join(", ", regressions))
						.append(System.lineSeparator());
			}
			throw new IllegalStateException(message.toString());
		}
	}

	private static void writePlanDump(Path outputDir, String queryId, String baselinePlan, String candidatePlan)
			throws IOException {
		Path plansDir = outputDir.resolve("plans");
		Files.createDirectories(plansDir);
		Path baselinePath = plansDir.resolve("query-" + queryId + "-baseline.txt");
		Path candidatePath = plansDir.resolve("query-" + queryId + "-candidate.txt");
		Files.writeString(baselinePath, baselinePlan, StandardCharsets.UTF_8);
		Files.writeString(candidatePath, candidatePlan, StandardCharsets.UTF_8);
	}

	private static Map<String, Long> toMultiset(List<BindingSet> bindings) {
		Map<String, Long> counts = new HashMap<>();
		for (BindingSet bindingSet : bindings) {
			String key = bindingSetKey(bindingSet);
			counts.merge(key, 1L, Long::sum);
		}
		return counts;
	}

	private static String bindingSetKey(BindingSet bindingSet) {
		List<String> names = new ArrayList<>(bindingSet.getBindingNames());
		names.sort(String::compareTo);
		return names.stream()
				.map(name -> name + "=" + bindingSet.getValue(name))
				.collect(Collectors.joining("|"));
	}

	private static void collectEstimationErrors(String queryId, GenericPlanNode node, String nodeId,
			List<EstimationError> errors) {
		Double estimate = node.getResultSizeEstimate();
		Long actual = node.getResultSizeActual();
		if (estimate != null && actual != null && estimate > 0 && actual > 0) {
			double ratio = Math.max(actual / estimate, estimate / actual);
			errors.add(new EstimationError(queryId, nodeId, node.getType(), estimate, actual, ratio));
		}
		List<GenericPlanNode> children = node.getPlans();
		if (children == null) {
			return;
		}
		for (int i = 0; i < children.size(); i++) {
			collectEstimationErrors(queryId, children.get(i), nodeId + "." + i, errors);
		}
	}

	private static void printSummary(String profile, RunResult result, Path outputPath) throws IOException {
		List<EstimationError> topErrors = result.estimationErrors.stream()
				.sorted(Comparator.comparingDouble((EstimationError error) -> error.ratio).reversed())
				.limit(10)
				.collect(Collectors.toList());

		StringBuilder summary = new StringBuilder();
		summary.append(profile).append(" worst estimation errors").append(System.lineSeparator());
		for (EstimationError error : topErrors) {
			summary.append(String.format("query=%s node=%s op=%s ratio=%.2f estimate=%.2f actual=%d",
					error.queryId, error.nodeId, error.opType, error.ratio, error.estimate, error.actual))
					.append(System.lineSeparator());
		}
		Files.writeString(outputPath, summary.toString(), StandardCharsets.UTF_8);
	}

	private static final class RunResult {
		private final String profile;
		private final Map<String, QueryOutcome> outcomes = new HashMap<>();
		private final List<EstimationError> estimationErrors = new ArrayList<>();

		private RunResult(String profile) {
			this.profile = profile;
		}
	}

	private static final class QueryOutcome {
		private final Map<String, Long> multiset;
		private final double totalTimeMs;
		private final String planText;
		private final List<EstimationError> estimationErrors;

		private QueryOutcome(Map<String, Long> multiset, double totalTimeMs, String planText,
				List<EstimationError> estimationErrors) {
			this.multiset = multiset;
			this.totalTimeMs = totalTimeMs;
			this.planText = planText;
			this.estimationErrors = estimationErrors;
		}
	}

	private static final class EstimationError {
		private final String queryId;
		private final String nodeId;
		private final String opType;
		private final double estimate;
		private final long actual;
		private final double ratio;

		private EstimationError(String queryId, String nodeId, String opType, double estimate, long actual,
				double ratio) {
			this.queryId = queryId;
			this.nodeId = nodeId;
			this.opType = opType;
			this.estimate = estimate;
			this.actual = actual;
			this.ratio = ratio;
		}
	}
}
